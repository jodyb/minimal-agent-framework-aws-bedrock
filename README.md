# Minimal Agent Framework

A lightweight agent framework built with LangGraph. Demonstrates core agent patterns including explicit state management, tool orchestration, guardrails, and policy-driven decision making.

## Features

- **Explicit State** - TypedDict-based state with full visibility into agent reasoning
- **LangGraph Integration** - Externalized control flow via graph-based orchestration
- **REASON/THINK Separation** - Control plane (policy, transitions) vs cognitive artifacts (reasoning notes)
- **Self-Describing Tools** - MCP-style registry with cost/risk/latency metadata
- **Guardrails** - Step limits, retrieval caps, tool failure tracking, tool budget limits
- **Policy-Driven Tool Selection** - Runtime control via `max_tool_risk` parameter
- **Tool Repair** - Automatic retry with LLM-guided repair on failures
- **Rich Observability** - Structured execution trace with timing, LLM call tracking, and decision rationale

## Architecture

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   REASON    │────▶│    THINK    │────▶│    TOOL     │
│  (control)  │◀────│  (cognition)│◀────│  (execute)  │
└─────────────┘     └─────────────┘     └─────────────┘
       │                                       │
       ▼                                       ▼
┌─────────────┐                         ┌─────────────┐
│  RETRIEVE   │                         │   ANSWER    │
└─────────────┘                         └─────────────┘
```

- **REASON** - Decides next action based on state, knowledge, and policy; records decision rationale
- **THINK** - Generates reasoning notes; handles tool repair proposals
- **TOOL** - Executes tools and validates outputs; tracks budget consumption
- **RETRIEVE** - Fetches knowledge (stub; extensible for RAG)
- **ANSWER** - Produces final response

### Observability & Execution Trace

The agent provides comprehensive observability through a structured event system. Every significant action emits an event with timing information, enabling detailed debugging and performance analysis.

#### Event Types

| Event Type | Description |
|------------|-------------|
| `llm_call` | LLM invocation with purpose, duration, and token estimates |
| `plan_created` | Short-horizon plan generated by REASON node |
| `plan_step` | Execution of a planned step |
| `plan_invalidated` | Plan dropped due to changed conditions |
| `tool_request` | Tool call initiated |
| `tool_executed` | Tool execution completed (success or failure) |
| `think_complete` | THINK node output with mode (reasoning/repair) |
| `retrieve_complete` | Document retrieval results with previews |
| `memory_compressed` | Memory summarization triggered |
| `routing` | Control flow decision |
| `guardrail` | Safety limit triggered |
| `rationale` | Human-readable explanation of why a decision was made |

#### Timing

All events include `ts_ms` (milliseconds since run start), enabling:
- Step-by-step timing analysis
- LLM latency tracking
- Bottleneck identification

#### Decision Rationale

Rationale is fully event-driven via `{"type": "rationale", "step": N, "text": "..."}` events. Each rationale explains *why* a decision was made, including:
- What alternatives were considered
- What constraints were applied (budgets, risk limits)
- What evidence informed the choice

To extract rationale programmatically:
```python
from agent.trace import extract_rationale, extract_rationale_text

# Get structured rationale
rationales = extract_rationale(final_state)  # [{"step": 1, "text": "...", "ts_ms": 123}, ...]

# Get simple text list
texts = extract_rationale_text(final_state)  # ["[1] Created plan...", "[2] Executing..."]
```

#### Trace Export

Every run is automatically exported to `./runs/<run_id>.json` for later analysis:

```python
from agent.trace import export_trace, load_trace, list_traces

# Export after a run
trace_path = export_trace(final_state)

# Load a previous trace
trace = load_trace("./runs/abc123.json")

# List all saved traces
traces = list_traces()  # Returns paths, newest first
```

Exported JSON structure:
```json
{
  "run_id": "abc123",
  "question": "What is 2+2?",
  "events": [...],
  "summary": {"step_count": 3, "tool_calls": 1, ...},
  "answer": "The result is 4.",
  "exported_at": "2024-01-15T10:30:00Z"
}
```

## Project Structure

```
├── main.py                 # Entry point
├── pyproject.toml          # Dependencies (uv/pip)
├── runs/                   # Exported trace files (gitignored)
├── src/
│   └── agent/
│       ├── lg_graph.py     # LangGraph definition
│       ├── lg_nodes.py     # Node implementations + event emission
│       ├── lg_state.py     # State schema (TypedDict)
│       ├── llm.py          # LLM interface (AWS Bedrock)
│       ├── tools.py        # Tool implementations
│       ├── tool_registry.py# Self-describing tool registry
│       ├── retrieve.py     # Knowledge retrieval (RAG stub)
│       ├── pretty_print.py # Execution trace formatting
│       └── trace.py        # Trace export to JSON
```

## Setup

### Prerequisites

- Python 3.11+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip
- AWS account with Bedrock access enabled
- AWS CLI configured with valid credentials

### Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/minimal-agent-framework.git
cd minimal-agent-framework

# Create virtual environment and install dependencies
uv venv
uv sync
```

### Running

```bash
uv run python main.py
```

Edit the `question` variable in `main.py` to test different inputs:

```python
question = "12*(3+4)"           # Calculator tool
question = "What is LangGraph?" # Retrieval + answer
question = "1/0"                # Tool failure → repair → retry
```

## AWS Bedrock Setup

This project uses AWS Bedrock for LLM inference. You need valid AWS credentials with Bedrock access.

### Configure AWS Credentials

Choose one method:

```bash
# Option A: AWS CLI (recommended)
aws configure

# Option B: Environment variables
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret
export AWS_DEFAULT_REGION=us-east-1
```

### Model Configuration

The default model is Claude 3 Haiku. Override via environment variables:

```bash
export BEDROCK_MODEL_ID=anthropic.claude-3-sonnet-20240229-v1:0
export AWS_DEFAULT_REGION=us-west-2
```

Available models:
- `anthropic.claude-3-haiku-20240307-v1:0` (default, fast/cheap)
- `anthropic.claude-3-sonnet-20240229-v1:0` (balanced)
- `anthropic.claude-3-opus-20240229-v1:0` (most capable)

> **Note:** Never commit AWS credentials. Use environment variables or AWS CLI profiles.

## Extending

### Adding Tools

Add new tools in `src/agent/tools.py`:

```python
from agent.tool_registry import register_tool

def my_tool(arg: str) -> dict:
    return {"tool": "my_tool", "input": {"arg": arg}, "output": {"result": "..."}, "ok": True}

register_tool({
    "name": "my_tool",
    "description": "Does something useful.",
    "input_schema": {
        "type": "object",
        "properties": {"arg": {"type": "string"}},
        "required": ["arg"],
    },
    "handler": my_tool,
    "cost": "low",      # low | medium | high
    "risk": "low",      # low | medium | high
    "latency_ms": 100,
})
```

### Adding Retrieval Sources

Extend `src/agent/retrieve.py` with embeddings, vector stores, or external APIs.

## Configuration

Key state parameters in `main.py`:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `max_steps` | 12 | Maximum reasoning steps |
| `retrieve_cap` | 2 | Maximum retrieval attempts |
| `tool_fail_cap` | 4 | Tool failures before giving up |
| `tool_call_cap` | 5 | Maximum total tool calls allowed |
| `tool_latency_cap_ms` | 10 | Maximum cumulative tool latency (ms) |
| `max_tool_risk` | "medium" | Maximum allowed tool risk level |
| `memory_every` | 4 | Steps between memory summarization |

## Example Output

Running `uv run python main.py` with a knowledge question:

```
=== ANSWER ===
A practical agent is a goal-directed state machine where an LLM helps choose transitions and code enforces guardrails.

=== FINAL STATE ===
next: ANSWER
step_count: 3
retrieve_count: 1
tool_fail_count: 0 last_error=None

=== TOOL BUDGET ===
calls: 0/5
latency: 0ms used, 10000ms remaining (cap: 10000ms)

=== EXECUTION TRACE ===

Step 1:
  - LLM CALL: plan_generation (245ms, ~156→42 tokens)
  - PLAN CREATED: ['RETRIEVE', 'ANSWER']
  - WHY: Created plan ['RETRIEVE', 'ANSWER'] (have_knowledge=False, have_tool_results=False)...

Step 2: (+250ms)
  - PLAN STEP → RETRIEVE
  - RETRIEVE COMPLETE: 1 docs (2ms) ["A practical agent is a goal-direct..."]
  - WHY: Executing plan step RETRIEVE: fetching knowledge (retrieve_count=0/2)...

Step 3: (+5ms)
  - PLAN STEP → ANSWER
  - WHY: Executing plan step ANSWER: sufficient evidence gathered to formulate response...
```

Running with a math expression (`question = "2 + 2"`):

```
=== ANSWER ===
The result is 4.0.

=== EXECUTION TRACE ===

Step 1:
  - TOOL REQUEST: calculator
  - WHY: Fast-path: detected math expression '2 + 2'; bypassing planning and routing...

Step 1:
  - TOOL EXECUTED: calculator (ok)

Step 2: (+52ms)
  - ROUTING → ANSWER (calculator_done)
```

## License

MIT

## Contributing

Contributions welcome! Please open an issue or PR.
